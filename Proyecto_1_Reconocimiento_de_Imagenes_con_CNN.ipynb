{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Este es un proyecto de reconocimiento de imágenes mediante el uso de una red neuronal convolusional o CNN. A tal fin, creo un set con fotos de tornillos y tarugos plásticos (para fijación en muros). Luego se hace un preprocesado de las imágenes, se arma la estructura de la CNN y se entrena para su posterior prueba clasificando. El set de imágenes se deja en el repositorio así, aquel que desee probar su funcionamiento, pueda hacerlo sin problemas."
      ],
      "metadata": {
        "id": "abHlwjBpULil"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bh-Vx76i5IWk"
      },
      "outputs": [],
      "source": [
        "# Importamos las librerías necesarias:\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "variable_name = \"\"\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import sys\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import cv2\n",
        "import math\n",
        "import os\n",
        "import io\n",
        "import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.python.keras.layers import  Convolution2D, Activation\n",
        "from tensorflow.python.keras import optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, classification_report,  mean_squared_error, r2_score, plot_confusion_matrix\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAFTZkPpzNR3"
      },
      "outputs": [],
      "source": [
        "# Subimos el archivo .Zip con las imágenes:\n",
        "from google.colab import files\n",
        "upfiles = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy09cJTLthDg"
      },
      "outputs": [],
      "source": [
        "# Descomprimimos el archivo:\n",
        "data = zipfile.ZipFile(io.BytesIO(upfiles['SET_CNN.zip']),'r')\n",
        "data.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una lista con las imágenes de la carpeta \"tornillos\" (si queremos podemos\n",
        "# convertir las imágenes a escala de grises), reescalamos el tamaño de las mismas\n",
        "# y la transformamos en un array de numpy:\n",
        "path_tor = '/content/tornillos/'\n",
        "list_tor = []\n",
        "size_tor = 150\n",
        "\n",
        "for Tornis in os.listdir(path_tor):\n",
        "  Tornis = cv2.imread(os.path.join(path_tor,Tornis))\n",
        "  resize_Tornis = cv2.resize(Tornis,(size_tor,size_tor))\n",
        "  list_tor.append(resize_Tornis)\n",
        "\n",
        "# Si quisieramos pasar las imágenes a escala de grises, usamos este otro ciclo for:\n",
        "#for Tornis in os.listdir(path_tor):\n",
        "#  Tornis = cv2.imread(os.path.join(path_tor,Tornis))\n",
        "#  gray_Tornis = cv2.cvtColor(Tornis,cv2.COLOR_BGR2GRAY)\n",
        "#  gray_resize_Tornis =cv2.resize(gray_Tornis,(tor_size,tor_size))\n",
        "#  list_tor.append(gray_resize_Tornis)\n",
        "\n",
        "list_tor = np.array(list_tor)\n",
        "\n",
        "# Vemos como quedó:\n",
        "print(\"Tamaño lista Tornillos:\",len(list_tor))\n",
        "print(list_tor.shape)"
      ],
      "metadata": {
        "id": "d-Sv4KHC-sYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una lista con las imágenes de la carpeta \"tarugos\" (si queremos podemos\n",
        "# convertir las imágenes a escala de grises), reescalamos el tamaño de las mismas\n",
        "# y la transformamos en un array de numpy:\n",
        "path_tar = '/content/tarugos/'\n",
        "list_tar = []\n",
        "size_tar = 150\n",
        "\n",
        "for Tarug in os.listdir(path_tar):\n",
        "  Tarug = cv2.imread(os.path.join(path_tar,Tarug))\n",
        "  resize_Tarug = cv2.resize(Tarug,(size_tar,size_tar))\n",
        "  list_tar.append(resize_Tarug)\n",
        "\n",
        "# Si quisieramos pasar las imágenes a escala de grises, usamos este otro ciclo for:\n",
        "#for Tarug in os.listdir(path_tar):\n",
        "#  Tarug = cv2.imread(os.path.join(path_tar,Tarug))\n",
        "#  gray_Tarug = cv2.cvtColor(Tarug,cv2.COLOR_BGR2GRAY)\n",
        "#  gray_resize_Tarug =cv2.resize(gray_Tarug,(tar_size,tar_size))\n",
        "#  list_tar.append(gray_resize_Tarug)\n",
        "\n",
        "list_tar = np.array(list_tar)\n",
        "\n",
        "# Vemos como quedó:\n",
        "print(\"Tamaño lista Tarugos:\",len(list_tar))\n",
        "print(list_tar.shape)"
      ],
      "metadata": {
        "id": "AtcOY-2b-sbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unimos ambos conjuntos de imágenes:\n",
        "dataImg = np.concatenate([list_tor,list_tar])\n",
        "print(len(dataImg))\n",
        "print(dataImg.shape)"
      ],
      "metadata": {
        "id": "P8nfbK9M-sgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la etiqueta \"TORNILLO\" para las imágenes de tornillos:\n",
        "label_tor = np.repeat(0,90)\n",
        "print(len(label_tor))\n",
        "print(label_tor)\n",
        "\n",
        "# Creamos la etiqueta \"TARUGO\" para las imágenes de tarugos:\n",
        "label_tar = np.repeat(1,90)\n",
        "print(len(label_tar))\n",
        "print(label_tar)\n",
        "\n",
        "# Definimos las clases:\n",
        "class_names = ['TORNILLO','TARUGO']\n",
        "\n",
        "# Teniendo en cuenta el orden de las etiquetas, las unimos:\n",
        "labels = np.concatenate([label_tor,label_tar])\n",
        "print(len(labels))\n",
        "print(labels)\n",
        "\n",
        "# Convertimos \"labels\" en un array:\n",
        "Labels = np.array(labels)\n",
        "print(Labels.shape)"
      ],
      "metadata": {
        "id": "CitqVHd1-si1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobamos con algunas imágenes que éstas ya tienen sus respectivas etiquetas:\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(10):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(dataImg[i])\n",
        "  cmap = plt.cm.binary\n",
        "  plt.xlabel(class_names[Labels[i]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fsok3I4N-smP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separamos el set en conjuntos de entrenamiento y validación:\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataImg, Labels, test_size=0.2, random_state=20)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "hf33OiXn-spi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el modelo de red neuronal convulsional:\n",
        "cnn = tf.keras.models.Sequential()\n",
        "cnn.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "cnn.add(tf.keras.layers.Conv2D(180, (5, 5), padding='same', activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "cnn.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "cnn.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "cnn.add(tf.keras.layers.Conv2D(360, (5, 5), padding='same', activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "cnn.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "cnn.add(tf.keras.layers.Conv2D(640, (5, 5), padding='same', activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "cnn.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "cnn.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "cnn.add(tf.keras.layers.Conv2D(640, (5, 5), padding='same', activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "cnn.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "cnn.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "cnn.add(tf.keras.layers.Conv2D(360, (5, 5), padding='same', activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "cnn.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "cnn.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "cnn.add(tf.keras.layers.Conv2D(180, (5, 5), padding='same', activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "cnn.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(180))\n",
        "cnn.add(tf.keras.layers.Activation('relu'))\n",
        "cnn.add(tf.keras.layers.Dropout(0.))\n",
        "cnn.add(tf.keras.layers.Dense(2))\n",
        "cnn.add(tf.keras.layers.Activation('softmax'))"
      ],
      "metadata": {
        "id": "1NDHbKVQ5DuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilamos el modelo:\n",
        "cnn.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1YHgPW0w5D_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos la extensión TensorBoard:\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Borramos cualquier log de ejecuciones previas:\n",
        "%rm -rf ./logs/\n",
        "\n",
        "# Colocamos los registros en un subdirectorio con marca de tiempo:\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "metadata": {
        "id": "6ammeW4ALrpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos nuestro modelo:\n",
        "TrainCnn = cnn.fit(X_train, y_train, batch_size=9, epochs=4, verbose=1, callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "id": "28u6sVBXImrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iniciamos Tensorboard:\n",
        "%tensorboard --logdir logs/fit"
      ],
      "metadata": {
        "id": "UDNY00rbMLFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# También podemos ver el resultado de la función de pérdida en cada época asi:\n",
        "plt.xlabel(\"# Epoch\")\n",
        "plt.ylabel(\"Magnitud de Pérdida\")\n",
        "plt.plot(TrainCnn.history[\"loss\"])"
      ],
      "metadata": {
        "id": "nb_5vNGgImtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exportamos del modelo en archivos h5. Así guardamos los pesos, los sesgos de la\n",
        "# red y el estado del optimizador para utlizarlo más adelante o en otro proyecto:\n",
        "# Recordad descargar los archivos a su equipo para volver a subirlos después, ya\n",
        "# que al finalizar la sesión de Colab estos se perderán.\n",
        "cnn.save('modelo_cnn.h5')\n",
        "cnn.save_weights('pesos_cnn.h5')"
      ],
      "metadata": {
        "id": "Hx93ih21Imvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------- ATENCION ----------------------------------#\n",
        "# De ser necesario, acá podemos volver a montar la CNN con los valores del modelo\n",
        "# y los pesos que habíamos exportado. Así, podemos hacer uso de la red neuronal \n",
        "# sin necesidad de volver a entrenarla:\n",
        "modelo = '/content/modelo_cnn.h5'\n",
        "pesos_modelo = '/content/pesos_cnn.h5'\n",
        "cnn = load_model(modelo)\n",
        "cnn.load_weights(pesos_modelo)"
      ],
      "metadata": {
        "id": "6MNEndXdTREy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ahora podemos elegir una imágen de las 180 del dataset y ver su clasificación:\n",
        "a = int(input(\"Ingrese un nro del 1 al 180 para seleccionar una imágen y que ésta sea clasificada: \"))\n",
        "imgP = dataImg[a]\n",
        "print(imgP.shape)\n",
        "imgP = (np.expand_dims(imgP,0))\n",
        "print(imgP.shape)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(dataImg[a])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "Predic = cnn.predict(imgP)\n",
        "print(Predic)\n",
        "print(np.sum(Predic))\n",
        "print(np.argmax(Predic))\n",
        "print(\"Esta imágen corresponde a un\", class_names[np.argmax(Predic)])"
      ],
      "metadata": {
        "id": "jBIBxEDsqSIf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}